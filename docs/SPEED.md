# Ускорение работы агентов (LLM)

## Что уже сделано

### 1. Параллельный запуск в оркестраторе

- **Vision и Classification** выполняются **одновременно** (два потока). Раньше шли подряд — теперь время первого этапа примерно в 2 раза меньше.
- **Pricing и Description** после сбора данных тоже запускаются **параллельно**. Самый долгий этап (генерация синтетических данных + CatBoost) идёт вместе с генерацией текста — общее время анализа уменьшается на время более быстрого из них.

### 2. Меньше строк в агенте цены

- В `pricing.py` число сгенерированных LLM строк уменьшено с 80 до **20**. Этого достаточно для обучения CatBoost; ответ по цене приходит быстрее (порядка 1–2 минут вместо 10+).

---

## Что ещё можно сделать

### Выбор модели

- **Быстрая модель для части агентов:** через переменные окружения задать более быструю модель (например `gpt-4o-mini`) для агентов, где допустим компромисс по качеству:
  - рекомендатор по фото;
  - при желании — генерация синтетических данных в pricing (остальная логика без изменений).
- В `client.py` уже используется `OPENAI_MODEL`; можно ввести `OPENAI_FAST_MODEL` и вызывать её в отдельных агентах.

### Меньше входных данных

- **Ограничить число фото в запросе к LLM:** например, отправлять в vision и classification не все загруженные фото, а первые 3–5. Меньше токенов → быстрее и дешевле. Имеет смысл предупреждать пользователя: «Для анализа используются первые 5 фото».

### Кэш

- **Кэш оценки цены:** для одного и того же набора полей (марка, модель, год, пробег и т.д.) не вызывать LLM+CatBoost повторно, а отдавать сохранённый результат (in-memory или Redis) с TTL 5–15 минут.

### Стриминг

- **Стриминг ответа при генерации описания:** не ждать полный текст, а отдавать его по мере появления (streaming API). Время до первого ответа уменьшится, пользователь быстрее увидит результат.

### Асинхронный расчёт цены

- При очень долгом ответе от pricing (например при 30+ строках) можно выносить задачу в фоновую очередь и возвращать ответ по готовности (polling или WebSocket), чтобы не держать HTTP-запрос несколько минут.

---

## Итог

Сейчас ускорение достигается за счёт **параллельного выполнения** агентов и **уменьшения объёма генерации** в pricing. Дальше можно точечно подключать быстрые модели, кэш и стриминг под ваши приоритеты по скорости и качеству.
